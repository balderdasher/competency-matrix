本章主要从以下4个方面介绍Java内存模型：

- **Java内存模型基础**：内存模型相关的基本概念
- **Java内存模型中的顺序一致性**：重排序与顺序一致性内存模型
- **同步原语**：`synchronized`、`volatile`和`final`的内存语义及重排序规则在处理器中的实现
- **Java内存模型的设计**：Java内存模型的设计原理以及与处理器内存模型和顺序一致性内存模型的关系

## 3.1 Java内存模型的基础 ##

并发编程中面临的两个关键问题：

1. 线程之间如何通信
2. 线程之间如何同步

通信是指线程之间以何种机制来交换信息。线程之间的通信机制有两种：**共享内存**和**消息传递**。

在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行**隐式**通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消息来进行**显式**通信。

*同步是指程序中用于控制不同线程间操作发生相对顺序的机制*。在共享内存并发模型里的同步是**显式**进行的。我们必须显式指定某个方法或代码段需要在线程之间互斥执行。而在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是**隐式**进行的。

*Java的并发采用共享内存模型*，Java线程之间的通信总是隐式进行。

### 3.1.1 Java内存模型的抽象结构 ###

> 在Java中，所有`实例域`、`静态域`和`数组元素`都存储在**堆内存**中，堆内存在线程之间共享。`局部变量`，`方法定义参数`和`异常处理参数`不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。

Java线程之间的通信由Java内存模型（`JMM`）控制，`JMM`决定一个线程对共享变量的写入何时对另一个线程可见。JMM定义了线程和主内存之间的抽象关系：*线程之间的共享变量存储在主内存（`Main Memory`）中，每个线程都有一个私有的本地内存（`Local Memory`），本地内存中存储了该线程以读/写共享变量的副本*。本地内存是JMM的一个抽象概念并不真实存在，它涵盖了`缓存`、`写缓冲区`、`寄存器`及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：

![Java-memory-model](http://i.imgur.com/4eP73mh.png)

根据上图，线程A与线程B通信的步骤如下：

- 线程A把本地内存A中更新过的共享变量刷新到主内存中去
- 线程B到主内存中去读取线程A之前已更新过的共享变量

具体通信过程如下图所示：

![communicate-steps](http://i.imgur.com/gm89KJV.png)

### 3.1.2 源代码到指令序列的重排序 ###

> 在执行程序时，为了提高性能，编译器和处理器常常会对指令进行重排序，重排序分为3中类型：
> 1. **编译器优化的重排序**：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序
> 2. **指令级并行的重排序**：现代处理器采用的指令级并行技术（`Instruction-LevelParallelism，ILP`）来将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序
> 3. **内存系统的重排序**：由于处理器使用缓存和读/写缓冲区，使得加载和存储操作看上去可能是在乱序执行

从Java源码到最终执行的指令序列的排序经过如下图所示：

![reorder](http://i.imgur.com/G4FFKSN.png)

图中的2和3属于处理器重排序，这些重排序可能会导致多线程程序出现内存可见性问题，对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时插入特定类型的内存屏障（`Memory Barriers`Intel称为`Memory Fence`）指令，通过内存屏障指令来禁止特定类型的处理器重排序，从而提供一致的内存可见性保证。

内存屏障类型表：

屏障类型|指令示例|说明
---|---|---
LoadLoad Barriers|Load1;LoadLoad;Load2|确保Load1数据的装在先于Load2及所有后续装载指令的装载
StoreStore Barriers|Store1;StoreStore;Store2|确保Store1数据对其他处理器可见（刷新到内存）先于Store2及所有后续存储指令的存储
LoadStore Barriers|Load1;LoadStore;Store2|确保Load1数据装载先于Store2及所有后续的存储指令刷新到内存
StoreLoad Barriers|Store1;StoreLoad;Load2|确保Store1数据对其他处理器变得可见（指刷新到内存）先于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令

`StoreLoad Barriers`是一个“全能型”的屏障，它同时具有其他3个屏障的效果，执行该屏障开销很大，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（`Buffer Fully Flush`）。

### 3.1.3 什么是happens-before? ###

> JDK 5开始，Java使用新的`JSR-133`内存模型。此模型使用`happens-before`的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在`happens-before`关系。这两个操作可以在一个线程之内，也可以在不同线程之间。

所谓的`happens-before`规则如下：

- **程序顺序规则**：一个线程中的每个操作，`happens-before`于该线程中的任意后续操作
- **监视器锁规则**：对一个锁的解锁，`happens-before`于随后对这个锁的加锁
- **`volatile`变量规则**：对一个`volatile`域的写，`happens-before`于任意后续对这个域的读
- **传递性**：如果`A happens-before B`，且`B happens-before C`，那么`A happens-before C`

**注意**：两个操作之间具有happens-before关系，并不代表前一个操作必须要在后一个操作之前执行，happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

## 3.2 重排序 ##

> 重排序是指编译器和处理器为了优化程序性能而对指令进行重新排序的一种手段。

### 3.2.1 数据依赖性 ###

> 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在**数据依赖性**，数据依赖性分为以下三种类型：

名称|代码示例|说明
:---|:---|---
写后读|`a = 1;`<br>`b = a;`|写一个变量之后，再读这个位置
写后写|`a = 1;`<br>`a = 2;`|写一个变量之后，再写这个变量
读后写|`a = b;`<br>`b = 1;`|读一个变量之后，再写这个变量

对于上表中的三种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变，所以，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序。这里说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。

### 3.2.2 as-if-serial ###

> `as-if-serial`语义的意思是：无论如何重排序，（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

为了遵守`as-if-serial`语义，编译器和处理器不会对有数据依赖关系的操作做重排序，因为重排序会改变执行结果，如果不存在数据依赖关系，这些操作就可能被重排序。如以下代码：

```java
double pi = 3.14;			// A
double r  = 1.0;			// B
double area = pi * r * r;	// C
```

以上代码中，`A`和`B`与`C`之间都存在数据依赖关系，因此在最终执行的指令序列中，C不能被重排序到A和B的前面，但A和B之间没有数据依赖关系，它们之间的执行顺序可以重排序，因此会产生两种可能的执行顺序：`A→B→C`或`B→A→C`。

as-if-serial语义把单线程程序保护了起来，所以会给我们一个幻觉：单线程程序是按照程序被编写的顺序来执行的。`as-if-serial`语义使我们再编写单线程程序时不用担心重排序会干扰它们，也无需担心内存可见性问题。3.

### 3.2.3 重排序对多线程的影响 ###

如有以下代码，假设有线程A和B，A首先执行`writer()`方法，随后B执行`reader()`方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？

```java
package com.mrdios.competencymatrix.concurrency.chapter3_JavaMemoryModel;

/**
 * 重排序对多线程的影响
 *
 * @author MrDios
 * @date 2017-06-08
 */
public class ReorderExample {
    int a = 0;              // 共享变量a
    boolean flag = false;   // 标识a是否已被写入

    public void writer() {
        a = 1;              // 1
        flag = true;        // 2
    }

    public void reader() {
        if (flag) {         // 3
            int i = a * a;  // 4
            System.out.println(i);
        }
    }
}
```

由于操作1和操作2、操作3和操作4两两之间都没有数据依赖关系，所以编译器和处理器可以对这两个操作重排序：

- 操作1和操作2重排序时：线程A先标记变量`flag`，随后B读共享变量`a`，因为flag已标记，线程B将读取变量a。此时变量a还没有被线程A写入，多线程程序的语义被重排序破坏了。
- 操作3和操作4重排序时：操作3和4存在控制依赖关系。当代码存在此种依赖时，会影响指令序列执行的并行度。所以，编译器和处理器会采用`猜测(Speculation)执行`来克服控制相关性对并行度的影响，此处以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算`a * a`,然后把计算结果临时保存到一个名为`重排序缓冲(Reorder Buffer,ROB)`的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中，同样破坏了多线程程序的语义（*我觉得简直是多此一举啊，那如果判断不为真的话猜测的计算岂不是白做了既浪费计算时间又浪费存储空间，正常根据判断来效率更高一些，有控制依赖的操作我觉得应该禁止重排序*）

综上所述，单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是`as-if-serial`语义允许对存在控制依赖的操作重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序可能会改变程序的执行结果。

## 3.3 顺序一致性 ##

> 顺序一致性内存模型是一个呗计算机科学家理想化了的理论化参考模型，它为程序员提供了极强的内存可见性保证，顺序一致性内存模型有两大特征：
> - 一个线程中的所有操作必须按照程序的顺序来执行
> - （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见

以下是顺序一致性内存模型为程序员提供的视图：

![顺序一致性内存模型](http://i.imgur.com/pDOh3Zh.png)

顺序一致性内存模型有一个单一的全局内存，此内存通过一个左右摆动的开关可以连接到任意一个线程，同时每个线程必须按照程序的顺序来执行内存读/写操作。由上图可知，在任意时间点最多只能有一个线程可以连接到内存，当多个线程并发执行时，图中哦的开关装置把所有线程的所有内存读/写操作串行化（即在顺序一致性模型中，所有操作之间具有全序关系）。


## 3.4 volatile ##

理解`volatile`特性的一个好方法是把对`volatile`变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。如以下示例：

```java
public class VolatileFeatureExample {
    volatile long v = 0L;           // 使用volatile声明64位的long型变量

    public void set(long l) {
        v = l;                      // 单个volatile变量的写操作
    }

    public void getAndIncrement() {
        v++;                        // 复合（多个）volatile变量的读/写
    }

    public long get() {
        return v;                   // 单个volatile量的读操作
    }
}
```

假如有多个线程分别调用以上程序的3个方法，此程序在语义上等价于下面的程序：

```java
public class VolatileFeatureExample {
    long v = 0L;                   // 不使用volatile声明时需要加同步

    // 对单个普通变量的写用同一个锁同步
    public synchronized void setV1(long l){
        v = l;
    }

    public void getAndIncrement(){// 普通方法调用
        long temp = get();        // 调用已同步的方法
        temp += 1L;               // 普通写操作
        setV(temp);               // 调用已同步的方法
    }

    public synchronized long get(){
        return v;
    }
}
```

如代码所示：一个`volatile`变量的单个读/写操作，与一个普通变量的读/写操作都是使用同一个锁来同步，它们的执行效果相同。

锁的`happens-before`规则保证释放锁和获取锁的两个线程之间的内存可见性，意味着对一个`volatile`变量的读，总是能看到（任意线程）对这个变量最后的写入。

简而言之：volatile变量自身具有以下特性：

- **可见性**：对一个`volatile`变量的读，总是能看到（任意线程）对这个变量最后的写入。
- **原子性**：对任意单个`volatile`变量的读/写操作具有原子性，但类似于`volatile++`这种复合操作不具有原子性。

### volatile写-读的内存语义 ###

有如下程序：

```java
public class ReorderExample {
    int a = 0;              // 共享变量a
    volatile boolean flag = false;   // 标识a是否已被写入

    public void writer() {
        a = 1;              // 1
        flag = true;        // 2
    }

    public void reader() {
        if (flag) {         // 3
            int i = a * a;  // 4
            System.out.println(i);
        }
    }
}
```

设线程A执行`writer()`方法，随后线程B执行`reader()`方法。下图是A执行volatile写后，共享变量`flag`的状态示意图：

![volatile-share](http://i.imgur.com/B3duMxF.png)

所以，**`volatile`写的内存语义是**：当写一个`volatile`变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。

线程B执行`reader()`方法时，本地内存B包含的值被置为无效，线程B必须从主内存中读取共享变量，这使得本地内存B与主存中的共享变量的值变成一致。

所以，**`volatile`读的内存语义是**：当读一个`volatile`变量时，JMM会把该线程对应的本地内存置为无效，线程将从主内存中读取共享变量。

volatile语义总结：

- 线程A写一个`volatile`变量，实质上是线程A向接下来将要读这个`volatile`变量的某个线程发出了（其对共享变量所做修改的）消息。
- 线程B读一个`volatile`变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。
- 线程A写一个`volatile`变量，随后线程B读到这个变量，这个过程实质上是线程A通过主内存向线程B发送消息

![](http://i.imgur.com/Hrp34YZ.png)

总结起来其实就是：多线程环境中针对volatile变量的读写都必须经过主内存，写操作把变量的更新刷新到主内存；读操作忽略该线程的本地内存直接从主内存读取（本地内存被置为无效）。

## 3.5 锁的内存语义 ##

锁的释放和获取的内存语义相对于volatile的写/读的内存语义如出一辙：

- 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中
- 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。

公平锁和非公平锁的内存语义：

- 公平锁和非公平锁释放锁时，最后都要写一个`volatile`变量的`state`
- 公平锁获取时，首先会去读`volatile`变量
- 非公平锁获取时，首先会用`CAS`更新`volatile`变量，这个操作同时具有`volatile`读和写的内存语义

锁释放-获取的内存语义的实现至少有以下两种（通过对`ReentrantLock`的分析）：

1. 利用`volatile`变量的写-读所具有的内存语义（公平锁）
2. 利用`CAS`所附带的volatile读和写的内存语义（非公平锁）

### concurrent包的实现 ###

> 由于Java的CAS同时具有volatile读和写的内存语义，因此Java线程之间的通信有如下4种方式
>     1. A线程写volatile变量，随后B线程读这个volatile变量
>     2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量
>     3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量
>     4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量

Java的CAS会使用现代处理器上提供的高效机器级别的原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是多处理器中实现同步的关键，同时，`volatile`变量的读/写和CAS可以实现线程之间的通信，二者结合就形成了整个`concurrent`包得以实现的基础，concurrent包有一个通用化的实现模式：

- 首先，声明共享变量为`volatile`
- 然后，使用`CAS`的原子条件更新来实现线程之间的同步
- 同时，配合以`volatile`的读/写和`CAS`所具有的volatile读/写的内存语义来实现线程之间的通信

concurrent包的实现示意图如下所示：

![](http://i.imgur.com/tdvwoPU.png)

## 3.6 final域的内存语义 ##

> 与锁和volatile相比，对`final`域的读和写更像是普通的变量访问

### 3.6.1 final域的重排序规则 ###

对于final域，编译器和处理器要遵守以下两个重排序规则：

1. 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
2. 初次读一个包含final域的对象引用，与随后初次读这个final域，这两个操作之间不能重排序。

### 3.6.2 写final域的重排序规则 ###

写final域的重排序规则禁止把final域的写重排序到构造函数之外，此规则包含以下两个方面：

1. JMM禁止编译器把final域的写重排序到构造函数之外
2. 编译器会在final域的写之后，构造函数return之前，插入一个`StoreStore`屏障。此屏障禁止处理器把final域的写重排序到构造函数之外

写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域不具有这个保障。


### 3.6.3 读final域的重排序规则 ###

> 读final域的重排序规则是：在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作（仅针对处理器），编译器会在读final域操作的前面插入一个`LoadLoad`屏障。

读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读包含这个final域的对象的引用。

### 3.6.4 final域为引用类型 ###

> 对于引用类型，写final域的重排序规则对编译器和处理器增加了如下约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。

### 3.6.5 为什么final引用不能从构造函数内“溢出” ###

> 如之前所述，写final域的重排序规则可以保证在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实要达到这个效果，还需要一个保证：**在构造函数内部，不能让这个被构造对象的引用为其他线程所见**，也就是说**对象引用不能再构造函数中“溢出”**

有如下示例代码：

```java
package com.mrdios.competencymatrix.concurrency.chapter3_JavaMemoryModel;

/**
 * final引用不能从构造函数逸出
 *
 * @author MrDios
 * @date 2017-06-09
 */
public class FinalReferenceEscapeExample {
    final int i;
    static FinalReferenceEscapeExample obj;

    public FinalReferenceEscapeExample() {
        i = 1;          // 1 写final域
        obj = this;     // 2 this引用在此“逸出”
    }

    public static void writer() {
        new FinalReferenceEscapeExample();
    }

    public static void reader() {
        if (obj != null) {      // 3
            int temp = obj.i;   // 4
        }
    }
}
```

书中说，在以上代码中，操作2使得对象还未完成构造前就为执行read方法的线程可见，某个执行`read()`方法的线程仍然可能无法看到final域被初始化之后的值。因为这里的1和2之间可能被重排序，此时`obj！=null`，所以`int temp = obj.i`读到的final域将是初始化之前的值。所以在构造函数返回前，被构造对象的引用不能被其他线程所见，因为此时的final域可能还没有被初始化。

但是一句上面所说的final域的重排序规则的第一条，以上代码中的操作1和操作2好像应该是不可以被重排序的啊，这我就有点懵了。

### 3.6.7 为什么要增强final的语义 ###

> 在旧的Java内存模型中，有一个严重的缺陷：线程看到的final域的值可能会变（正常final域是不应该改变的），比如final的int由0变成了1，`String`的值甚至也在改变。
> JSR-133为解决这个bug，增强了final的语义。通过为final域增加些和读重排序规则，为我们提供了初始化安全保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有逸出），那么不需要使用同步（指`lock`和`volatile`的使用）就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。

## 3.7 happens-before ##

`《JSR-133:Java Memory Model and Thread Specification》`对`happens-before`关系的定义如下：
 
- 如果一个操作`happens-before`另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。**这是JMM对程序员的承诺**
- 两个操作之间存在`happens-before`关系，并不意味着Java平台的具体实现必须按照`happens-before`关系指定的顺序来执行。如果重排序之后的执行结果与按`happens-before`关系来执行的结果一致，那么这种重排序并不违法（JMM允许这种重排序）。**这是JMM对编译器和处理器重排序的约束原则**



